{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd943540-a544-4972-9893-7890ce60e065",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Capstone Project - Malay Language Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20751a75-bf57-4bbe-acbe-7aa43846531a",
   "metadata": {},
   "source": [
    "## Part 4 - Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b0956-c1ff-4770-8e86-88fbff763a20",
   "metadata": {},
   "source": [
    "In this notebook, we will go through the steps to:\n",
    "1. Create a Flask API based on the best model\n",
    "2. Create a Dockerfile\n",
    "3. Deploy to Google Cloud\n",
    "4. Host on Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbbe57-f73d-4bb5-bba4-db98237da6b5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 1. Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18f2dcc-add5-4ec0-b5b3-483c59c7e140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment.py \n",
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "#import your_nlp_library as nlp\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load your NLP model here (replace with actual loading code)\n",
    "# Example:\n",
    "with open('03_production_sentiment_model.pkl', 'rb') as file:\n",
    "    # Unpickle the object\n",
    "    model = pickle.load(file)\n",
    "\n",
    "@app.route('/predict_sentiment', methods=['POST'])\n",
    "def predict_sentiment():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        sentences = data['sentences']\n",
    "\n",
    "        # Join the sentences into a single string\n",
    "        input_text = ' '.join(sentences)\n",
    "\n",
    "        # Get probabilities for each class\n",
    "        prediction_proba = model.predict_proba([input_text])[0]\n",
    "\n",
    "        # Determine the class based on the highest probability\n",
    "        class_labels = ['negative', 'neutral', 'positive']\n",
    "        sentiment = class_labels[np.argmax(prediction_proba)]\n",
    "\n",
    "        # Round the probabilities to 2 significant figures\n",
    "        probabilities = [round(prob, 2) for prob in prediction_proba]\n",
    "\n",
    "        response = {'sentiment': sentiment, 'probability': probabilities}\n",
    "        return jsonify(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)})\n",
    "\n",
    "if __name__ == '__main__': # good practise to have this main block whenever creating a .py file\n",
    "    app.run(host='0.0.0.0', # run the 'api' object created above with 2 routes on local host url '0.0.0.0' to just run on this computer\n",
    "            debug=True, # Debug=True ensures any changes to inference.py (like adding an extra print somewhere in this script) automatically updates the running API\n",
    "            port=int(os.environ.get(\"PORT\", 8081)) # just use 8080 by default. This 8080 runs the API locally\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123384d0-cf8f-45d2-854c-78e4a1b45e75",
   "metadata": {},
   "source": [
    "At this point, open a terminal in this folder and enter:\n",
    "\n",
    "```bash\n",
    "mamba activate malay_sentiment_project\n",
    "```\n",
    "and\n",
    "\n",
    "```bash\n",
    "python sentiment.py\n",
    "```\n",
    "\n",
    "<mark>**Note:**</mark>This is based on the virtual environment we created in Notebook 01. If you created a virtual environment that is named differently, mamba activate that virtual environment.\n",
    "\n",
    "Then, run the code cell below to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e5256d6-b9be-4055-8662-b88452e12ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment prediction: {'probability': [0.6, 0.24, 0.16], 'sentiment': 'negative'}\n"
     ]
    }
   ],
   "source": [
    "#Testing script\n",
    "\n",
    "import requests\n",
    "\n",
    "# Define the URL of your Flask app\n",
    "url = 'http://127.0.0.1:8081/predict_sentiment'  # Replace with the actual URL\n",
    "\n",
    "# Define the input data as a dictionary\n",
    "data = {\n",
    "    'sentences': [\n",
    "        'kau dh knp ni?'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send a POST request to the Flask app\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    result = response.json()  # Parse the JSON response\n",
    "    print('Sentiment prediction:', result)\n",
    "else:\n",
    "    print('Error:', response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84725ea2-cd5d-4ccc-af78-db200555f29c",
   "metadata": {},
   "source": [
    "## 2. Create Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a1a1e-cd99-48c4-a4c0-be200f1aa1d9",
   "metadata": {},
   "source": [
    "Now that we know that the API works, create a Dockerfile to put on Google Cloud so that the API is hosted there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa44d9a-40be-4edd-ac3c-fc361847b2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "# Use the official Python image\n",
    "FROM python:3.8-slim\n",
    "\n",
    "# Set the working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy your Flask application and model file\n",
    "COPY sentiment.py .\n",
    "COPY 03_production_sentiment_model.pkl .\n",
    "\n",
    "# Install any necessary Python libraries for your Flask app\n",
    "RUN pip install flask joblib requests scikit-learn pandas numpy imbalanced-learn\n",
    "\n",
    "# Expose the port your Flask app will run on\n",
    "EXPOSE 8081\n",
    "\n",
    "# Run the Flask app\n",
    "CMD [\"python\", \"sentiment.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdbe195-1cff-4554-9bb1-9dfd8686c27f",
   "metadata": {},
   "source": [
    "## 3. Deploy to Google Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06630e-7099-4c55-bb91-9a8c1933e764",
   "metadata": {},
   "source": [
    "At this point, open a terminal in this folder and run:\n",
    "\n",
    "```bash\n",
    "gcloud run deploy malay-sentiment-analysis --source . --region asia-southeast1\n",
    "```\n",
    "<mark>**Note:**</mark> Choose a region of your choice.\n",
    "\n",
    "Type y to ANY message you get on your terminal and press 'return'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b75630ea-2442-44f3-8f7b-bdce1cc49f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': [0.6, 0.24, 0.16], 'sentiment': 'negative'}\n"
     ]
    }
   ],
   "source": [
    "# Testing the cloud-hosted API\n",
    "import requests\n",
    "\n",
    "api_url = 'https://malay-sentiment-analysis-nqaybcgjca-as.a.run.app'\n",
    "api_route = '/predict_sentiment'\n",
    "\n",
    "user_input = {'sentences': ['kau dh knp ni?']} \n",
    "\n",
    "response = requests.post(f'{api_url}{api_route}', json = user_input)\n",
    "predictions = response.json()\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4b9b2-dd3d-4b3a-98b7-3dcf2caeec79",
   "metadata": {},
   "source": [
    "## 4. Host on Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2fc107-7684-404a-842a-6ddee7fdb21f",
   "metadata": {},
   "source": [
    "Finally, host it on Streamlit. \n",
    "1. Run the code below\n",
    "2. Copy the 'malay_sentiment_analysis_streamlit.py' script to your relevant GitHub folder\n",
    "3. git push to your personal GitHub\n",
    "4. Sign up for [Streamlit Cloud](https://streamlit.io/cloud) and connect it to your personal GitHub\n",
    "5. Create a 'New app' from existing repo and ensure that the repository, branch, and main file path point towards the 'malay_sentiment_analysis_streamlit.py' script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec93a33-f459-4a4e-bfc7-49b5235b2892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting malay_sentiment_analysis_streamlit.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile malay_sentiment_analysis_streamlit.py\n",
    "import streamlit as st\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#st.set_page_config(page_title=\"Alat Analisis Sentiment Media Sosial\")\n",
    "st.set_page_config(page_title=\"Social Media Sentiment Analysis Tool\")\n",
    "\n",
    "# Title of the webpage\n",
    "#st.title(\"Alat Analisis Sentiment Media Sosial ðŸ“ŠðŸ‘¥ðŸ’¬\")\n",
    "st.title(\"Social Media Sentiment Analysis Tool (Bahasa Melayu) ðŸ“ŠðŸ‘¥ðŸ’¬\")\n",
    "\n",
    "# Create an empty container to hold the user input\n",
    "user_input_container = st.empty()\n",
    "\n",
    "# Get user inputs\n",
    "sentence = user_input_container.text_area(label='Input a sentence in Malay to determine its sentiment. ðŸ‡¸ðŸ‡¬ðŸ‡²ðŸ‡¾ðŸ‡§ðŸ‡³ðŸ‡®ðŸ‡©')\n",
    "#sentence = user_input_container.text_area(label='Isi ayat dalam Bahasa Melayu untuk menentukan sentimen ayat tersebut. ðŸ‡¸ðŸ‡¬ðŸ‡²ðŸ‡¾ðŸ‡§ðŸ‡³ðŸ‡®ðŸ‡©')\n",
    "\n",
    "# Display the inputs\n",
    "user_input = {\"sentences\": [sentence]} \n",
    "st.write(\"User input:\")\n",
    "st.write(user_input)\n",
    "\n",
    "# Code to post the user inputs to the API and get the predictions\n",
    "# Paste the URL to your GCP Cloud Run API here!\n",
    "api_url = 'https://malay-sentiment-analysis-nqaybcgjca-as.a.run.app'  # replace with own Google Cloud Run API\n",
    "api_route = '/predict_sentiment'\n",
    "\n",
    "# Add a submit button\n",
    "if st.button(\"Submit\"):  # only display model predictions on UI if user clicks \"Submit\" button\n",
    "    response = requests.post(f'{api_url}{api_route}', json=user_input)\n",
    "    predictions = response.json()  # return dictionary with key 'predictions' & values are a list of predictions\n",
    "    \n",
    "    st.write(f\"Sentiment: {predictions['sentiment']}\")  # prediction values were stored in 'predictions' key of dict: predictions. [0] is to give prediction output 0/1 in a \"unlisted\" format since we're only sending user inputs for 1 row of X at a time\n",
    "   # # Extract the sentiment probability from the dictionary\n",
    "   #  negative_probability = predictions[\"probability\"][0]\n",
    "   #  neutral_probability = predictions[\"probability\"][1]\n",
    "   #  positive_probability = predictions[\"probability\"][2]\n",
    "\n",
    "   #  # Create a dictionary to pass to st.bar_chart and round the values\n",
    "   #  chart_data = {\n",
    "   #      \"Sentiment\": [\"Negative\", \"Neutral\", \"Positive],\n",
    "   #      \"Probability\": [negative_probability, neutral_probability, positive_probability]\n",
    "   #  }\n",
    "\n",
    "   #  # Create a bar chart\n",
    "   #  st.bar_chart(chart_data, x=\"Sentiment\", y=\"Probability\", use_container_width=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

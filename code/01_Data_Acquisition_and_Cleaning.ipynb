{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5122cea6-1924-4447-b9ca-944fa0cf8705",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Capstone Project - Malay Language Social Media Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023124e-2b38-4695-98b4-7f2798a4c932",
   "metadata": {},
   "source": [
    "## Part 1 - Data Acquisition and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793aea26-b372-4754-8ca2-78cfeac93378",
   "metadata": {},
   "source": [
    "## 1. Introduction and Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af740b6b-758d-43fb-b3ed-75f466962c22",
   "metadata": {},
   "source": [
    "Sentiment analysis is a subfield of Natural Language Processing (NLP) that focuses on the detection of one's sentiment in text data. It is one of the most widely-used applications of NLP, and is important in a variety of areas including social media content, customer reviews, speech conversations, and news.\n",
    "\n",
    "Sentiment analysis allows organisations and individuals to understand views on their actions, and themselves. For organisations and individuals who want to track public opinion on them (ie. reputation management), sentiment analysis is vital to help them filter through enormous amounts of unstructured information.\n",
    "\n",
    "While research and development into sentiment analysis has been done quite comprehensively on major languages such as the English and Chinese languages, it has been really scarce for less popular languages such as Malay. As of today, there is only one well known Natural-Language-Toolkit library for Bahasa Melayu, which is [Malaya](https://malaya.readthedocs.io/en/stable/). In the library, there are a number of modules that can be used, including sentiment analysis.\n",
    "\n",
    "However, the sentiment analysis model used in Malaya appears to be lexicon-based. While lexicon-based models are common (eg. VADER) and interpretable, it is limited when it comes to handling contextual understanding, as well as vocabulary gaps. For the latter, it is important that the list of words in the lexicon is varied and robust in order to detect the right sentiments in varied types of sentences.\n",
    "\n",
    "However, diving into the [sentiment-specific lexicon](https://github.com/huseinzol05/malaysian-dataset/blob/master/lexicon/sentiment.json), it appears to be quite limited to formal Malay words, and is unlikely to be able to detect sentiments in texts which include slang or short-forms, which is very common in Malay social media.\n",
    "\n",
    "Based on this, the problem statement for my capstone is:\n",
    "\n",
    "**<center>Can we create an best-in-class classification model to identify sentiments in Malay social media comments?</center>**\n",
    "\n",
    "The ideal outcome / goal is to create an sentiment analysis model for Bahasa Melayu that is reasonably accurate for social media comments. In this project, I will compare the accuracy of the Malaya model in detecting sentiments, and compare it to the accuracy of ChatGPT 3.5, which is an existing Large Language Model that is trained on Bahasa Melayu (albeit less so than on English). Whichever model performs better, will be used as a baseline to train our model on.\n",
    "\n",
    "The primary audience will be individuals and organisations that wish to understand views of Malay-speakers on social media. These individuals and organisations will be primarily based in the Malay archipelago, which includes countries such as Malaysia, Indonesia, Singapore and Brunei, and has a combined population of close to 400 million people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1e3dd-db97-40a7-bdc1-dfd1a41cb4dd",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition - YouTube Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2e212-d63b-4eef-b65e-22decc87a6c0",
   "metadata": {},
   "source": [
    "In this project, we will be working with one dataset - YouTube comments. The YouTube comments will be pulled from various videos which have comments primarily in Bahasa Melayu, and our goal will be to get sufficient comments with the various sentiments: positive, negative, and neutral.\n",
    "\n",
    "In this notebook, we will import the data before commencing data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4758f5-328b-4eb0-9433-3a3a6b0094f7",
   "metadata": {},
   "source": [
    "<mark>**Note:**</mark> Before importing libraries, I'd recommend creating a new environment due to certain version conflicts with pip installing and importing the Malaya model.\n",
    "\n",
    "To do so, run the following commands in the terminal in the same folder as the requirements.txt (assuming we are using mamba as an environment manager).\n",
    "\n",
    "1.\n",
    "```bash\n",
    "mamba create --name malay_sentiment_project\n",
    "```\n",
    "\n",
    "2.\n",
    "```bash\n",
    "mamba activate malay_sentiment_project\n",
    "```\n",
    "\n",
    "3.\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a7c3d4-6a24-489c-b62f-dd3d451084fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f15e3-982b-49c3-8ca5-8af3ba6cac7c",
   "metadata": {},
   "source": [
    "### 2.1 Comments Pull - Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad09d34-3c29-4082-8e97-16e00ce7b9c1",
   "metadata": {},
   "source": [
    "We will be doing 2 rounds of pulling comments in order not to reach our daily API limit. Thus, the pulling is done over two days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a66af6b-d5e8-4474-bec0-b696e6492c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube API Credentials\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"insert developer key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a372508e-19b3-4d52-9852-ba5a67bbfb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hafiz Khan</td>\n",
       "      <td>2023-09-06T07:52:06Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Org kelantan ke apa ji</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia Adriana</td>\n",
       "      <td>2023-08-18T05:07:29Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau lama pecah cermin tu n pichang la org dl...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdul mutalib</td>\n",
       "      <td>2023-08-10T11:29:37Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Patut kak tu diberi lesen mcine gun tembak mat...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdul mutalib</td>\n",
       "      <td>2023-08-10T11:28:47Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Mau langar smpai patah kaki ja... Tada kj samu...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syam Ryin</td>\n",
       "      <td>2023-08-08T12:50:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Mangsa Dalam kereta tu macam mna?diam je x beg...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NT H</td>\n",
       "      <td>2023-08-06T12:00:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>langgar je kasi mati terus. bugima btl</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Farizan Rili</td>\n",
       "      <td>2023-07-22T07:13:55Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Langar mati pun tak apa</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mohamad Anwar</td>\n",
       "      <td>2023-06-16T11:10:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Terbaik la tindakan sist.....</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ezaaq Eida</td>\n",
       "      <td>2023-06-16T09:44:11Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalu aku memang non stop doh tu langgar … biar...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dwi laksono</td>\n",
       "      <td>2023-06-10T14:35:51Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Knp dia stop ehh..klu aku dh tekan hon biar se...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author          published_at  like_count  \\\n",
       "0     Hafiz Khan  2023-09-06T07:52:06Z           0   \n",
       "1    Mia Adriana  2023-08-18T05:07:29Z           0   \n",
       "2  abdul mutalib  2023-08-10T11:29:37Z           0   \n",
       "3  abdul mutalib  2023-08-10T11:28:47Z           0   \n",
       "4      Syam Ryin  2023-08-08T12:50:10Z           0   \n",
       "5           NT H  2023-08-06T12:00:40Z           0   \n",
       "6   Farizan Rili  2023-07-22T07:13:55Z           0   \n",
       "7  Mohamad Anwar  2023-06-16T11:10:39Z           0   \n",
       "8     Ezaaq Eida  2023-06-16T09:44:11Z           0   \n",
       "9    dwi laksono  2023-06-10T14:35:51Z           0   \n",
       "\n",
       "                                                text  \\\n",
       "0                             Org kelantan ke apa ji   \n",
       "1  Kalau lama pecah cermin tu n pichang la org dl...   \n",
       "2  Patut kak tu diberi lesen mcine gun tembak mat...   \n",
       "3  Mau langar smpai patah kaki ja... Tada kj samu...   \n",
       "4  Mangsa Dalam kereta tu macam mna?diam je x beg...   \n",
       "5             langgar je kasi mati terus. bugima btl   \n",
       "6                            Langar mati pun tak apa   \n",
       "7                      Terbaik la tindakan sist.....   \n",
       "8  Kalu aku memang non stop doh tu langgar … biar...   \n",
       "9  Knp dia stop ehh..klu aku dh tekan hon biar se...   \n",
       "\n",
       "                                 video_title    video_published_at  \n",
       "0  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "1  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "2  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "3  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "4  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "5  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "6  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "7  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "8  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "9  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using YouTube API\n",
    "def get_video_comments(video_id, max_results=100, max_comments=10000):\n",
    "    youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "    \n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "    total_comments_fetched = 0\n",
    "    \n",
    "    while total_comments_fetched < max_comments:\n",
    "        remaining_comments_to_fetch = max_comments - total_comments_fetched\n",
    "        comments_to_fetch = min(max_results, remaining_comments_to_fetch)\n",
    "        \n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=comments_to_fetch,\n",
    "            pageToken=next_page_token if next_page_token else None\n",
    "        )\n",
    "        \n",
    "        response = request.execute()\n",
    "        \n",
    "        # Get the video information (title and upload date) for the first batch of comments\n",
    "        if total_comments_fetched == 0:\n",
    "            video_response = youtube.videos().list(\n",
    "                part=\"snippet\",\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "            \n",
    "            video_title = video_response['items'][0]['snippet']['title']\n",
    "            video_published_at = video_response['items'][0]['snippet']['publishedAt']\n",
    "        \n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append([\n",
    "                comment['authorDisplayName'],\n",
    "                comment['publishedAt'],\n",
    "                comment['likeCount'],\n",
    "                comment['textDisplay'],\n",
    "                video_title,  # Adding video title for each comment\n",
    "                video_published_at  # Adding video upload date for each comment\n",
    "            ])\n",
    "        \n",
    "        total_comments_fetched += comments_to_fetch\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "    \n",
    "    return comments\n",
    "\n",
    "# List of video IDs for which you want to fetch comments\n",
    "video_ids = [\"aUZoLk01OPo\", \"mZN0xnK4hBU\", \"TJ2INthzEis\", \"2ZpcdcjJ2hs\", \"JgyQ0v-7DS4\", \"GlO2sSuezXw\"]\n",
    "\n",
    "# Initialize an empty list to store all comments from multiple videos\n",
    "all_comments = []\n",
    "\n",
    "for video_id in video_ids:\n",
    "    comments_for_video = get_video_comments(video_id)\n",
    "    all_comments.extend(comments_for_video)\n",
    "\n",
    "# Create a DataFrame from all the comments\n",
    "df = pd.DataFrame(all_comments, columns=['author', 'published_at', 'like_count', 'text', 'video_title', 'video_published_at'])\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3625d051-4801-4caf-9f81-8061420cc49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15211, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe729d2-5434-412f-9aee-087908e806b0",
   "metadata": {},
   "source": [
    "There are over 15,000 comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1c62a6-2e80-459c-bfc0-8ece651afada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv\n",
    "df.to_csv('../data/01_raw_malay_comments_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70636c1c-334d-402c-ae15-da878f515413",
   "metadata": {},
   "source": [
    "### 2.2 Comments Pull - Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "561accfa-310d-4bab-a15f-4f5ff52d0c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Arnajirson</td>\n",
       "      <td>2023-08-18T07:56:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Setu saya nak bagi tahu,  Hal kecil pun jadi b...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zain Isa</td>\n",
       "      <td>2023-04-21T07:20:34Z</td>\n",
       "      <td>0</td>\n",
       "      <td>@SyamsulYusuf. 66 oi&amp;amp;gas!</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oudsatinmood A</td>\n",
       "      <td>2023-04-16T16:36:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>🤗</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lanun si kucing</td>\n",
       "      <td>2023-04-09T01:44:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Pasal cincin ke biar betul mat.  Ni mcm kes be...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yg Raja Putra</td>\n",
       "      <td>2023-04-07T05:34:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Biasalah artist mcm Diana, bila suami dak susa...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ahmad Yusof</td>\n",
       "      <td>2023-04-05T12:25:59Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau seorang isteri ditanya tentang org ketig...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pencinta Ustaz Wadi Annuar</td>\n",
       "      <td>2023-04-05T03:04:46Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Apa yang terbaik pasti akan terjadi seadanya 1...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oldmansingin love</td>\n",
       "      <td>2023-04-03T05:50:29Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Selamatlh mnjadi bini setan</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FA betta chanel</td>\n",
       "      <td>2023-04-02T18:41:16Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Wartawan pon batu api 🔥...  Dalam rumah tangga...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laili Mohd</td>\n",
       "      <td>2023-04-02T15:30:33Z</td>\n",
       "      <td>0</td>\n",
       "      <td>No3. To late the hero.</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       author          published_at  like_count  \\\n",
       "0            David Arnajirson  2023-08-18T07:56:39Z           0   \n",
       "1                    Zain Isa  2023-04-21T07:20:34Z           0   \n",
       "2              Oudsatinmood A  2023-04-16T16:36:24Z           0   \n",
       "3             lanun si kucing  2023-04-09T01:44:40Z           0   \n",
       "4               Yg Raja Putra  2023-04-07T05:34:00Z           0   \n",
       "5                 Ahmad Yusof  2023-04-05T12:25:59Z           0   \n",
       "6  Pencinta Ustaz Wadi Annuar  2023-04-05T03:04:46Z           0   \n",
       "7           oldmansingin love  2023-04-03T05:50:29Z           0   \n",
       "8             FA betta chanel  2023-04-02T18:41:16Z           0   \n",
       "9                  Laili Mohd  2023-04-02T15:30:33Z           0   \n",
       "\n",
       "                                                text  \\\n",
       "0  Setu saya nak bagi tahu,  Hal kecil pun jadi b...   \n",
       "1                      @SyamsulYusuf. 66 oi&amp;gas!   \n",
       "2                                                  🤗   \n",
       "3  Pasal cincin ke biar betul mat.  Ni mcm kes be...   \n",
       "4  Biasalah artist mcm Diana, bila suami dak susa...   \n",
       "5  Kalau seorang isteri ditanya tentang org ketig...   \n",
       "6  Apa yang terbaik pasti akan terjadi seadanya 1...   \n",
       "7                        Selamatlh mnjadi bini setan   \n",
       "8  Wartawan pon batu api 🔥...  Dalam rumah tangga...   \n",
       "9                             No3. To late the hero.   \n",
       "\n",
       "                                         video_title    video_published_at  \n",
       "0  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "1  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "2  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "3  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "4  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "5  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "6  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "7  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "8  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "9  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using YouTube API\n",
    "def get_video_comments(video_id, max_results=100, max_comments=10000):\n",
    "    youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "    \n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "    total_comments_fetched = 0\n",
    "    \n",
    "    while total_comments_fetched < max_comments:\n",
    "        remaining_comments_to_fetch = max_comments - total_comments_fetched\n",
    "        comments_to_fetch = min(max_results, remaining_comments_to_fetch)\n",
    "        \n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=comments_to_fetch,\n",
    "            pageToken=next_page_token if next_page_token else None\n",
    "        )\n",
    "        \n",
    "        response = request.execute()\n",
    "        \n",
    "        # Get the video information (title and upload date) for the first batch of comments\n",
    "        if total_comments_fetched == 0:\n",
    "            video_response = youtube.videos().list(\n",
    "                part=\"snippet\",\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "            \n",
    "            video_title = video_response['items'][0]['snippet']['title']\n",
    "            video_published_at = video_response['items'][0]['snippet']['publishedAt']\n",
    "        \n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append([\n",
    "                comment['authorDisplayName'],\n",
    "                comment['publishedAt'],\n",
    "                comment['likeCount'],\n",
    "                comment['textDisplay'],\n",
    "                video_title,  # Adding video title for each comment\n",
    "                video_published_at  # Adding video upload date for each comment\n",
    "            ])\n",
    "        \n",
    "        total_comments_fetched += comments_to_fetch\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "    \n",
    "    return comments\n",
    "\n",
    "# List of video IDs for which you want to fetch comments\n",
    "video_ids = [\"zMKC2nk0KoU\", \"W8cnupHVrXE\", \"Xtx5L4NEemg\", \"8VMFEuEQvd4\"]\n",
    "\n",
    "# Initialize an empty list to store all comments from multiple videos\n",
    "all_comments = []\n",
    "\n",
    "for video_id in video_ids:\n",
    "    comments_for_video = get_video_comments(video_id)\n",
    "    all_comments.extend(comments_for_video)\n",
    "\n",
    "# Create a DataFrame from all the comments\n",
    "df = pd.DataFrame(all_comments, columns=['author', 'published_at', 'like_count', 'text', 'video_title', 'video_published_at'])\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d44c83-06a0-4740-ae82-29a8e3d500b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10377, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294439b4-041a-4f9c-a252-cdc36b946f1e",
   "metadata": {},
   "source": [
    "There are over 10,000 comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e852e09-1fc1-4150-85ff-a99717cb96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv\n",
    "df.to_csv('../data/01_raw_malay_comments_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e624af9-02d6-4e1e-8eea-7993133cf20e",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271daa10-adf8-4836-aae8-7593bf6b3a3b",
   "metadata": {},
   "source": [
    "We will start off with data cleaning - focusing on null values, duplicated values, data types and HTML-encoded entities. But first, we will concatenate both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a03ed94-2187-42ac-8648-0830f689e927",
   "metadata": {},
   "source": [
    "### 3.1 Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f84fab0-0a17-4064-b3d0-8680f6c13fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/01_raw_malay_comments_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dbee84d-35dd-445a-b975-ef791cdee834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/01_raw_malay_comments_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a854a963-8604-4d9f-bca0-cddfbba4c5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hafiz Khan</td>\n",
       "      <td>2023-09-06T07:52:06Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Org kelantan ke apa ji</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia Adriana</td>\n",
       "      <td>2023-08-18T05:07:29Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau lama pecah cermin tu n pichang la org dl...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdul mutalib</td>\n",
       "      <td>2023-08-10T11:29:37Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Patut kak tu diberi lesen mcine gun tembak mat...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdul mutalib</td>\n",
       "      <td>2023-08-10T11:28:47Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Mau langar smpai patah kaki ja... Tada kj samu...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syam Ryin</td>\n",
       "      <td>2023-08-08T12:50:10Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Mangsa Dalam kereta tu macam mna?diam je x beg...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author          published_at like_count  \\\n",
       "0     Hafiz Khan  2023-09-06T07:52:06Z          0   \n",
       "1    Mia Adriana  2023-08-18T05:07:29Z          0   \n",
       "2  abdul mutalib  2023-08-10T11:29:37Z          0   \n",
       "3  abdul mutalib  2023-08-10T11:28:47Z          0   \n",
       "4      Syam Ryin  2023-08-08T12:50:10Z          0   \n",
       "\n",
       "                                                text  \\\n",
       "0                             Org kelantan ke apa ji   \n",
       "1  Kalau lama pecah cermin tu n pichang la org dl...   \n",
       "2  Patut kak tu diberi lesen mcine gun tembak mat...   \n",
       "3  Mau langar smpai patah kaki ja... Tada kj samu...   \n",
       "4  Mangsa Dalam kereta tu macam mna?diam je x beg...   \n",
       "\n",
       "                                 video_title    video_published_at  \n",
       "0  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "1  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "2  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "3  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "4  Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e716e6fd-132d-4298-8fa5-d8d7fd03bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Arnajirson</td>\n",
       "      <td>2023-08-18T07:56:39Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Setu saya nak bagi tahu,  Hal kecil pun jadi b...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zain Isa</td>\n",
       "      <td>2023-04-21T07:20:34Z</td>\n",
       "      <td>0</td>\n",
       "      <td>@SyamsulYusuf. 66 oi&amp;amp;gas!</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oudsatinmood A</td>\n",
       "      <td>2023-04-16T16:36:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>🤗</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lanun si kucing</td>\n",
       "      <td>2023-04-09T01:44:40Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Pasal cincin ke biar betul mat.  Ni mcm kes be...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yg Raja Putra</td>\n",
       "      <td>2023-04-07T05:34:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Biasalah artist mcm Diana, bila suami dak susa...</td>\n",
       "      <td>“Dia nak selamatkan muka dia” - Diana Danielle...</td>\n",
       "      <td>2023-03-28T05:21:54Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author          published_at like_count  \\\n",
       "0  David Arnajirson  2023-08-18T07:56:39Z          0   \n",
       "1          Zain Isa  2023-04-21T07:20:34Z          0   \n",
       "2    Oudsatinmood A  2023-04-16T16:36:24Z          0   \n",
       "3   lanun si kucing  2023-04-09T01:44:40Z          0   \n",
       "4     Yg Raja Putra  2023-04-07T05:34:00Z          0   \n",
       "\n",
       "                                                text  \\\n",
       "0  Setu saya nak bagi tahu,  Hal kecil pun jadi b...   \n",
       "1                      @SyamsulYusuf. 66 oi&amp;gas!   \n",
       "2                                                  🤗   \n",
       "3  Pasal cincin ke biar betul mat.  Ni mcm kes be...   \n",
       "4  Biasalah artist mcm Diana, bila suami dak susa...   \n",
       "\n",
       "                                         video_title    video_published_at  \n",
       "0  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "1  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "2  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "3  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  \n",
       "4  “Dia nak selamatkan muka dia” - Diana Danielle...  2023-03-28T05:21:54Z  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5829a0e9-9f8e-43f4-8ed2-a768ffc5f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a11abb13-8804-489b-9d70-3b22305e06b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>Muhammad Shafizan</td>\n",
       "      <td>2023-04-06T04:01:36Z</td>\n",
       "      <td>2</td>\n",
       "      <td>nasib baik button dislike tkboleh tngk berapa ...</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>Mr_Adam 92</td>\n",
       "      <td>2023-04-06T04:01:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>kepala cengkirit..tu je bleh cakap kbai</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>Sanjut x Gaming</td>\n",
       "      <td>2023-04-06T04:00:57Z</td>\n",
       "      <td>0</td>\n",
       "      <td>ayuh kasi dislike</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10383</th>\n",
       "      <td>nurhazirah lim</td>\n",
       "      <td>2023-04-06T04:00:46Z</td>\n",
       "      <td>1</td>\n",
       "      <td>😂😂😂😂</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>siti nurzafirah</td>\n",
       "      <td>2023-04-06T04:00:37Z</td>\n",
       "      <td>1</td>\n",
       "      <td>No syatuuuuu wak.😂😂😂</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author          published_at like_count  \\\n",
       "10380  Muhammad Shafizan  2023-04-06T04:01:36Z          2   \n",
       "10381         Mr_Adam 92  2023-04-06T04:01:19Z          0   \n",
       "10382    Sanjut x Gaming  2023-04-06T04:00:57Z          0   \n",
       "10383     nurhazirah lim  2023-04-06T04:00:46Z          1   \n",
       "10384    siti nurzafirah  2023-04-06T04:00:37Z          1   \n",
       "\n",
       "                                                    text  \\\n",
       "10380  nasib baik button dislike tkboleh tngk berapa ...   \n",
       "10381            kepala cengkirit..tu je bleh cakap kbai   \n",
       "10382                                  ayuh kasi dislike   \n",
       "10383                                               😂😂😂😂   \n",
       "10384                               No syatuuuuu wak.😂😂😂   \n",
       "\n",
       "                                             video_title    video_published_at  \n",
       "10380  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "10381  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "10382  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "10383  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "10384  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3d57f2-e882-4533-a023-9a088a356fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv\n",
    "df.to_csv('../data/01_raw_malay_comments.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ed4cb-90a2-4d42-8f72-f53a59ebfb83",
   "metadata": {},
   "source": [
    "### 3.2 Handling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a717747-d7fe-4729-af1f-28906eeea7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/01_raw_malay_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d4e7320-f7bf-400c-b59c-053a2b579a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25613 entries, 0 to 25612\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   author              25612 non-null  object\n",
      " 1   published_at        25592 non-null  object\n",
      " 2   like_count          25592 non-null  object\n",
      " 3   text                25581 non-null  object\n",
      " 4   video_title         25584 non-null  object\n",
      " 5   video_published_at  25584 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b2b3def-58f5-473c-b096-91f510dbf61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                 1\n",
       "published_at          21\n",
       "like_count            21\n",
       "text                  32\n",
       "video_title           29\n",
       "video_published_at    29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for columns with null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0f475a-95ea-4e57-9f52-6ea1519a46a6",
   "metadata": {},
   "source": [
    "There are a number of null values. Because they make up such a small amount of the total number of rows, we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4220a86-520e-4f97-af1f-e685109b4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping nulls\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51c7a34b-8b0c-45ca-9af9-8d35911f479b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                0\n",
       "published_at          0\n",
       "like_count            0\n",
       "text                  0\n",
       "video_title           0\n",
       "video_published_at    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double checking\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a1f435-83d8-49a0-929f-f2c62b1deccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25576 entries, 0 to 25612\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   author              25576 non-null  object\n",
      " 1   published_at        25576 non-null  object\n",
      " 2   like_count          25576 non-null  object\n",
      " 3   text                25576 non-null  object\n",
      " 4   video_title         25576 non-null  object\n",
      " 5   video_published_at  25576 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429007ff-0bf5-42ec-ac13-dea382dafd9d",
   "metadata": {},
   "source": [
    "### 3.3 Handling Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96dc075d-ae1d-4a13-9d06-97f7f1ea775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25576, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for the number of rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9353656-0f89-41f2-b697-391f6b212923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for number of duplicated comments\n",
    "df['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72efa9d2-2f3b-451c-8619-5683ba74cb61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Sherli Malinda</td>\n",
       "      <td>2020-11-19T14:04:55Z</td>\n",
       "      <td>0</td>\n",
       "      <td>SEORANG GADIS DI PERKOSA RAMAI RAMAI DAN DI RE...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>yt 12</td>\n",
       "      <td>2020-11-16T01:00:08Z</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"https://youtu.be/dClnptakA4g\"&gt;https:/...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Aci Uwa</td>\n",
       "      <td>2020-11-16T00:08:05Z</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"https://youtu.be/dClnptakA4g\"&gt;https:/...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Aci Uwa</td>\n",
       "      <td>2020-11-16T00:07:59Z</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"https://youtu.be/dClnptakA4g\"&gt;https:/...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Ali Redha</td>\n",
       "      <td>2020-10-23T12:28:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Jalankan undang-undang Islam, baru tak ada ora...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14T04:04:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25596</th>\n",
       "      <td>Rizu Iskandar</td>\n",
       "      <td>2023-04-06T04:04:14Z</td>\n",
       "      <td>2</td>\n",
       "      <td>🎉🎉</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25603</th>\n",
       "      <td>Chaimah gaming</td>\n",
       "      <td>2023-04-06T04:02:44Z</td>\n",
       "      <td>3</td>\n",
       "      <td>Done dislike</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25606</th>\n",
       "      <td>Julisham ajirul</td>\n",
       "      <td>2023-04-06T04:01:53Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Done dislike</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25607</th>\n",
       "      <td>eyman. ucop</td>\n",
       "      <td>2023-04-06T04:01:39Z</td>\n",
       "      <td>3</td>\n",
       "      <td>❤❤❤</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25611</th>\n",
       "      <td>nurhazirah lim</td>\n",
       "      <td>2023-04-06T04:00:46Z</td>\n",
       "      <td>1</td>\n",
       "      <td>😂😂😂😂</td>\n",
       "      <td>Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...</td>\n",
       "      <td>2023-04-06T04:00:10Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>815 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author          published_at like_count  \\\n",
       "516     Sherli Malinda  2020-11-19T14:04:55Z          0   \n",
       "542              yt 12  2020-11-16T01:00:08Z          0   \n",
       "543            Aci Uwa  2020-11-16T00:08:05Z          0   \n",
       "544            Aci Uwa  2020-11-16T00:07:59Z          0   \n",
       "683          Ali Redha  2020-10-23T12:28:31Z          0   \n",
       "...                ...                   ...        ...   \n",
       "25596    Rizu Iskandar  2023-04-06T04:04:14Z          2   \n",
       "25603   Chaimah gaming  2023-04-06T04:02:44Z          3   \n",
       "25606  Julisham ajirul  2023-04-06T04:01:53Z          2   \n",
       "25607      eyman. ucop  2023-04-06T04:01:39Z          3   \n",
       "25611   nurhazirah lim  2023-04-06T04:00:46Z          1   \n",
       "\n",
       "                                                    text  \\\n",
       "516    SEORANG GADIS DI PERKOSA RAMAI RAMAI DAN DI RE...   \n",
       "542    <a href=\"https://youtu.be/dClnptakA4g\">https:/...   \n",
       "543    <a href=\"https://youtu.be/dClnptakA4g\">https:/...   \n",
       "544    <a href=\"https://youtu.be/dClnptakA4g\">https:/...   \n",
       "683    Jalankan undang-undang Islam, baru tak ada ora...   \n",
       "...                                                  ...   \n",
       "25596                                                 🎉🎉   \n",
       "25603                                       Done dislike   \n",
       "25606                                       Done dislike   \n",
       "25607                                                ❤❤❤   \n",
       "25611                                               😂😂😂😂   \n",
       "\n",
       "                                             video_title    video_published_at  \n",
       "516            Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "542            Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "543            Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "544            Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "683            Respek kakak ni bertarung nyawa dan harta  2019-09-14T04:04:25Z  \n",
       "...                                                  ...                   ...  \n",
       "25596  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "25603  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "25606  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "25607  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "25611  Dato Sri Aliff Syukri - Chu Ku Chuk Raya [Offi...  2023-04-06T04:00:10Z  \n",
       "\n",
       "[815 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432435f7-1c26-42c9-9fd0-d27f85d350f9",
   "metadata": {},
   "source": [
    "There are a number of duplicated rows. Again, because they make up such a small amount of the total number of rows, we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "835edff6-292f-456f-a8f6-22f372889781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='text', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa18d0e9-17f6-47ca-9905-a655ae72efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8969c11-4705-4676-8155-3a138648c849",
   "metadata": {},
   "source": [
    "### 3.4 Handling Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6011d6f8-da50-42cd-b687-ae1240da7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24761 entries, 0 to 24760\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   author              24761 non-null  object\n",
      " 1   published_at        24761 non-null  object\n",
      " 2   like_count          24761 non-null  object\n",
      " 3   text                24761 non-null  object\n",
      " 4   video_title         24761 non-null  object\n",
      " 5   video_published_at  24761 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d436bd1-9151-48c4-bafc-b535da42185a",
   "metadata": {},
   "source": [
    "We have two columns that are meant to be datetimes:\n",
    "1. 'published_at'\n",
    "2. 'video_published_at'\n",
    "\n",
    "Let us change the type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6ccbeee-37ca-431f-81ec-edc632b2c921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting to datetime\n",
    "df['published_at'] = pd.to_datetime(df['published_at'])\n",
    "df['video_published_at'] = pd.to_datetime(df['video_published_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "358cfc58-ce16-4bc8-a9cb-e035f86fa07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24761 entries, 0 to 24760\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   author              24761 non-null  object             \n",
      " 1   published_at        24761 non-null  datetime64[ns, UTC]\n",
      " 2   like_count          24761 non-null  object             \n",
      " 3   text                24761 non-null  object             \n",
      " 4   video_title         24761 non-null  object             \n",
      " 5   video_published_at  24761 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the dtype\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8d8b4-83e0-4c57-bfad-c9b6f286ac28",
   "metadata": {},
   "source": [
    "### 3.5 Handling HTML-encoded entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679f8f1-cce3-4c07-82d0-b496d598dae7",
   "metadata": {},
   "source": [
    "Some of the comments can be quite confusing due to HTML-encoded entities. Thus, we will use BeautifulSoup to handle that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50926586-1b52-4ffd-8592-f5b8ace8c010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Z</td>\n",
       "      <td>2023-02-01 09:57:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Kamus Dewan Edisi 17, &lt;br&gt;~ Respek - Bahasa pa...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>Marvel Hulk87</td>\n",
       "      <td>2019-05-25 15:58:24+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Terbaek KC 💪💪💪&lt;br&gt;Tk pernah hampa kan peminat ...</td>\n",
       "      <td>Cerita dalam Kereta S2 Ep05 (Wanita Mati Dibun...</td>\n",
       "      <td>2019-05-25 14:28:49+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author              published_at like_count  \\\n",
       "32                Z 2023-02-01 09:57:11+00:00          0   \n",
       "5076  Marvel Hulk87 2019-05-25 15:58:24+00:00          3   \n",
       "\n",
       "                                                   text  \\\n",
       "32    Kamus Dewan Edisi 17, <br>~ Respek - Bahasa pa...   \n",
       "5076  Terbaek KC 💪💪💪<br>Tk pernah hampa kan peminat ...   \n",
       "\n",
       "                                            video_title  \\\n",
       "32            Respek kakak ni bertarung nyawa dan harta   \n",
       "5076  Cerita dalam Kereta S2 Ep05 (Wanita Mati Dibun...   \n",
       "\n",
       "            video_published_at  \n",
       "32   2019-09-14 04:04:25+00:00  \n",
       "5076 2019-05-25 14:28:49+00:00  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing example of HTML-encoded text\n",
    "df_html = pd.concat([df.iloc[32:33], df.iloc[5076:5077]])\n",
    "df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7e3bd01-676c-45e5-b5e1-e680422bd9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w4/0rkrlv1d2cg4g7rbby5yb_tr0000gn/T/ipykernel_4737/770990489.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  df['text'] = df['text'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n"
     ]
    }
   ],
   "source": [
    "# Using BeautifulSoup to handle HTML-encoded entities\n",
    "df['text'] = df['text'].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a12eaeb-8c7c-4f9d-8142-64cb537c11de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Z</td>\n",
       "      <td>2023-02-01 09:57:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Kamus Dewan Edisi 17, ~ Respek - Bahasa pasar ...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>Marvel Hulk87</td>\n",
       "      <td>2019-05-25 15:58:24+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Terbaek KC 💪💪💪Tk pernah hampa kan peminat Respect</td>\n",
       "      <td>Cerita dalam Kereta S2 Ep05 (Wanita Mati Dibun...</td>\n",
       "      <td>2019-05-25 14:28:49+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author              published_at like_count  \\\n",
       "32                Z 2023-02-01 09:57:11+00:00          0   \n",
       "5076  Marvel Hulk87 2019-05-25 15:58:24+00:00          3   \n",
       "\n",
       "                                                   text  \\\n",
       "32    Kamus Dewan Edisi 17, ~ Respek - Bahasa pasar ...   \n",
       "5076  Terbaek KC 💪💪💪Tk pernah hampa kan peminat Respect   \n",
       "\n",
       "                                            video_title  \\\n",
       "32            Respek kakak ni bertarung nyawa dan harta   \n",
       "5076  Cerita dalam Kereta S2 Ep05 (Wanita Mati Dibun...   \n",
       "\n",
       "            video_published_at  \n",
       "32   2019-09-14 04:04:25+00:00  \n",
       "5076 2019-05-25 14:28:49+00:00  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the changes on HTML-encoded text\n",
    "df_html = pd.concat([df.iloc[32:33], df.iloc[5076:5077]])\n",
    "df_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a1650-e962-44b5-8948-091d55ce4715",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d84b9-80ab-4452-88f0-5512b5ac6b39",
   "metadata": {},
   "source": [
    "To get more details of the comments, let us create a couple of columns: comment length and comment word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8061f26-8a6f-4f74-8557-7388679725a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column called comment_length\n",
    "df['comment_length'] = df['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f88938da-5365-480f-b706-bc60bfda52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column called comment_word_count\n",
    "df['comment_word_count'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca6122e5-8df5-4157-a5f6-093e776f026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>published_at</th>\n",
       "      <th>like_count</th>\n",
       "      <th>text</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_published_at</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>comment_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hafiz Khan</td>\n",
       "      <td>2023-09-06 07:52:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Org kelantan ke apa ji</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia Adriana</td>\n",
       "      <td>2023-08-18 05:07:29+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Kalau lama pecah cermin tu n pichang la org dl...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdul mutalib</td>\n",
       "      <td>2023-08-10 11:29:37+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Patut kak tu diberi lesen mcine gun tembak mat...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "      <td>143</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdul mutalib</td>\n",
       "      <td>2023-08-10 11:28:47+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Mau langar smpai patah kaki ja... Tada kj samu...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syam Ryin</td>\n",
       "      <td>2023-08-08 12:50:10+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Mangsa Dalam kereta tu macam mna?diam je x beg...</td>\n",
       "      <td>Respek kakak ni bertarung nyawa dan harta</td>\n",
       "      <td>2019-09-14 04:04:25+00:00</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author              published_at like_count  \\\n",
       "0     Hafiz Khan 2023-09-06 07:52:06+00:00          0   \n",
       "1    Mia Adriana 2023-08-18 05:07:29+00:00          0   \n",
       "2  abdul mutalib 2023-08-10 11:29:37+00:00          0   \n",
       "3  abdul mutalib 2023-08-10 11:28:47+00:00          0   \n",
       "4      Syam Ryin 2023-08-08 12:50:10+00:00          0   \n",
       "\n",
       "                                                text  \\\n",
       "0                             Org kelantan ke apa ji   \n",
       "1  Kalau lama pecah cermin tu n pichang la org dl...   \n",
       "2  Patut kak tu diberi lesen mcine gun tembak mat...   \n",
       "3  Mau langar smpai patah kaki ja... Tada kj samu...   \n",
       "4  Mangsa Dalam kereta tu macam mna?diam je x beg...   \n",
       "\n",
       "                                 video_title        video_published_at  \\\n",
       "0  Respek kakak ni bertarung nyawa dan harta 2019-09-14 04:04:25+00:00   \n",
       "1  Respek kakak ni bertarung nyawa dan harta 2019-09-14 04:04:25+00:00   \n",
       "2  Respek kakak ni bertarung nyawa dan harta 2019-09-14 04:04:25+00:00   \n",
       "3  Respek kakak ni bertarung nyawa dan harta 2019-09-14 04:04:25+00:00   \n",
       "4  Respek kakak ni bertarung nyawa dan harta 2019-09-14 04:04:25+00:00   \n",
       "\n",
       "   comment_length  comment_word_count  \n",
       "0              22                   5  \n",
       "1              50                  11  \n",
       "2             143                  25  \n",
       "3              54                  10  \n",
       "4              52                   9  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1b2ed8e-a552-45ca-b152-4445515879b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to csv file\n",
    "df.to_csv('../data/01_cleaned_malay_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
